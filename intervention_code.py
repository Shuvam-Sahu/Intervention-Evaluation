# -*- coding: utf-8 -*-
"""Intervention Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11h15yiD0bM4eA0D4jowhDsjgCI67HSaK
"""

import pandas as pd

# Load both datasets
student_data = pd.read_excel('Student Data.xlsx')
intervention_data = pd.read_excel('Intervention Report.xlsx')

# Merge using left join on Student ID
merged_data = pd.merge(student_data, intervention_data, left_on='Student ID', right_on='Student IDCode', how='left')

# Drop the duplicate 'Student IDCode' column after merging
merged_data = merged_data.drop(columns=['Student IDCode'])
merged_data = merged_data.drop(columns=['Year_y'])

# Step 1: Group by 'Student ID' and filter for students who are only in 2020
only_2020_students = merged_data.groupby('Student ID').filter(lambda x: (x['Year_x'] == 2020).all())

# Filter to check if there are any students in 2021 with NaN in the 'Group' column
nan_group_2021 = merged_data[(merged_data['Year_x'] == 2021) & (merged_data['Group'].isna())]

# Replace NaN in 'Group' column with 'Pre-Intervention'
merged_data['Group'] = merged_data['Group'].fillna('Pre-Intervention')

# Replace inconsistent 'Participated' or 'Did not participate' for 'Not in Intervention Group' with 'Not Invited'
merged_data.loc[(merged_data['Group'] == 'Not In Intervention Group') & (merged_data['Participation'] == 'Participated'), 'Participation'] = 'Not Invited'
merged_data.loc[(merged_data['Group'] == 'Not In Intervention Group') & (merged_data['Participation'] == 'Did not participate'), 'Participation'] = 'Not Invited'

# Now, handle any remaining NaN in Participation for those in 'Not in Intervention Group' with 'Not Invited'
merged_data.loc[(merged_data['Group'] == 'Not In Intervention Group') & (merged_data['Participation'].isna()), 'Participation'] = 'Not Invited'

# Now, handle any remaining NaN in Participation for those in 'Pre-Intervention' with 'Not Available'
merged_data.loc[(merged_data['Group'] == 'Pre-Intervention') & (merged_data['Participation'].isna()), 'Participation'] = 'Not Available'

# Filter data for students who participated in 2021
data_2021 = merged_data[merged_data['Year_x'] == 2021]

# Remove duplicates based on Student ID to ensure each student is counted only once
unique_participation_2021 = data_2021.drop_duplicates(subset='Student ID')

# Calculate the overall participation rate for 2021 students
participation_rate_2021 = unique_participation_2021['Participation'].value_counts(normalize=True) * 100

# Output the results
print("Overall Participation Rate for 2021 Students:")
print(participation_rate_2021)

# Create a new column to group invited students (Did not participate + Participated) and Not Invited
data_2021['Group_Category'] = data_2021['Participation'].apply(lambda x: 'Not Invited' if x == 'Not Invited' else 'Invited')

# List of attributes we want to analyze
attributes = ['Passed', 'Good Pass', 'Submitted First Assessment', 'Ethnicity', 'Disability Type', 'New or Continuing Student', 'IMD']

# Function to calculate percentage breakdown for each attribute by Group_Category
def calculate_attribute_pct(attribute, data):
    return data.groupby('Group_Category')[attribute].value_counts(normalize=True).unstack() * 100

    # Loop through the attributes and print percentage breakdown for each Group_Category
for attribute in attributes:
    print(f"\n{attribute} Percentage Breakdown by Group Category (Not Invited vs. Invited):")
    attribute_pct = calculate_attribute_pct(attribute, data_2021)
    print(attribute_pct)

    # Overall Pass Rates by Year
pass_rate_by_year = merged_data.groupby('Year_x')['Passed'].value_counts(normalize=True).unstack() * 100
print("Overall Pass Rates by Year (2020 vs. 2021):")
print(pass_rate_by_year)

# 1. Pass Rates by Ethnicity, Grouped by Year
pass_rate_by_ethnicity_year = merged_data.groupby(['Year_x', 'Ethnicity'])['Passed'].value_counts(normalize=True).unstack() * 100
print("Pass Rates by Ethnicity and Year:")
print(pass_rate_by_ethnicity_year)

# 2. Pass Rates by Disability Type, Grouped by Year
pass_rate_by_disability_year = merged_data.groupby(['Year_x', 'Disability Type'])['Passed'].value_counts(normalize=True).unstack() * 100
print("\nPass Rates by Disability Type and Year:")
print(pass_rate_by_disability_year)

# 3. Pass Rates by IMD Quintile, Grouped by Year
pass_rate_by_imd_year = merged_data.groupby(['Year_x', 'IMD'])['Passed'].value_counts(normalize=True).unstack() * 100
print("\nPass Rates by IMD and Year:")
print(pass_rate_by_imd_year)

# 4. Pass Rates by New or Continuing Student Status, Grouped by Year
pass_rate_by_student_status_year = merged_data.groupby(['Year_x', 'New or Continuing Student'])['Passed'].value_counts(normalize=True).unstack() * 100
print("\nPass Rates by New or Continuing Student and Year:")
print(pass_rate_by_student_status_year)

# 1. Pass Rates by Ethnicity, Grouped by Year
Good_pass_rate_by_ethnicity_year = merged_data.groupby(['Year_x', 'Ethnicity'])['Good Pass'].value_counts(normalize=True).unstack() * 100
print("Good Pass Rates by Ethnicity and Year:")
print(Good_pass_rate_by_ethnicity_year)

# 2. Pass Rates by Disability Type, Grouped by Year
Good_pass_rate_by_disability_year = merged_data.groupby(['Year_x', 'Disability Type'])['Good Pass'].value_counts(normalize=True).unstack() * 100
print("\nGood Pass Rates by Disability Type and Year:")
print(Good_pass_rate_by_disability_year)

# 3. Pass Rates by IMD Quintile, Grouped by Year
Good_pass_rate_by_imd_year = merged_data.groupby(['Year_x', 'IMD'])['Good Pass'].value_counts(normalize=True).unstack() * 100
print("\nGood Pass Rates by IMD and Year:")
print(Good_pass_rate_by_imd_year)

# 4. Pass Rates by New or Continuing Student Status, Grouped by Year
Good_pass_rate_by_student_status_year = merged_data.groupby(['Year_x', 'New or Continuing Student'])['Good Pass'].value_counts(normalize=True).unstack() * 100
print("\nGood Pass Rates by New or Continuing Student and Year:")
print(Good_pass_rate_by_student_status_year)

# Step 1: Identify students who appear in both 2020 and 2021
students_2020 = merged_data[merged_data['Year_x'] == 2020]['Student ID'].unique()
students_2021 = merged_data[merged_data['Year_x'] == 2021]['Student ID'].unique()
common_students = set(students_2020).intersection(students_2021)

# Step 2: Filter the DataFrame for these common students
common_students_data = merged_data[merged_data['Student ID'].isin(common_students)]

# Step 3: Calculate pass and "Good Pass" rates for these students by year
# Pass Rates
pass_rate_by_year_common = common_students_data.groupby('Year_x')['Passed'].value_counts(normalize=True).unstack() * 100
print("Pass Rates by Year for Students Present in Both 2020 and 2021:")
print(pass_rate_by_year_common)

# "Good Pass" Rates
good_pass_rate_by_year_common = common_students_data.groupby('Year_x')['Good Pass'].value_counts(normalize=True).unstack() * 100
print("\nGood Pass Rates by Year for Students Present in Both 2020 and 2021:")
print(good_pass_rate_by_year_common)

from google.colab import files
merged_data.to_excel("merged_data.xlsx", index=False)
files.download("merged_data.xlsx")